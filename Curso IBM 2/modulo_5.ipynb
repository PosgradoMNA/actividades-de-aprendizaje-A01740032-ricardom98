{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 4 - Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Materia: Ciencia y Analítica de Datos\n",
    "<br>\n",
    "Alumno: Ricardo Morales Bustillos\n",
    "<br>\n",
    "Matrícula: A017400321"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simpliest way to obtain cross validation\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# scores = cross_val_score(lr, x_data, y_data, cv=3) commented to avoid error\n",
    "\n",
    "# if we want more information we do\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "# scores = cross_val_predict(lr2e, x_data, y_data, cv=3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overfitting, Underfitting and Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rsqu_test = []  #we create an empty list to store the values\n",
    "order = [1,2,3,4] #We create a list containing different polynomial orders.\n",
    "\n",
    "for n in order:\n",
    "    pr = PolynomialFeature(degree=n) #We create a polynomial feature object with the order of the polynomial as a parameter\n",
    "    x_train_pr = pr.fit_transform(x_train[['horsepower']]) # We transform the training and test data into a polynomial using the fit transform method\n",
    "    x_test_pr = pr.fit_transform(x_test[['horsepower']])\n",
    "    lr.fit(x_train_pr, y_train) # We fit the regression model using the transformed data\n",
    "    Rsqu_test.append(lr.score(x_test_pr,y_test)) # We then calculate the R-squared using the test data and store it in the array.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge regression controls the magnitude of these polynomial coefficients by introducing the parameter alpha\n",
    "# Alpha must be carefully selected to avoid under and over fitting\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "RidgeModel = Ridge(alpha=0.1)\n",
    "RidgeModel.fit(X,y)\n",
    "\n",
    "Yhat = RidgeModel.predict(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search allows us to scan through multiple free parameters and find the best hyperparameters that minimizes/maximizes the error\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters1= ['alpha': [0.001,0.1,1, 10, 100, 1000,10000,100000,100000]1/\n",
    "RR=Ridge()\n",
    "Grid1 = GridSearchCV(RR, parameters1,cv=4)\n",
    "Grid1.fit(x_data[l'horsepower', 'curb-weight', 'engine-size', 'highway-mpg'll,y_data)\n",
    "Grid1.best estimator\n",
    "scores = Grid1.cv_results\n",
    "scores['mean test score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUESTION 1\n",
    "x_train1, x_test1, y_train1, y_test1 = train_test_split(x_data, y_data, test_size=0.4, random_state=0) \n",
    "print(\"number of test samples :\", x_test1.shape[0])\n",
    "print(\"number of training samples:\",x_train1.shape[0])\n",
    "\n",
    "# QUESTION 2\n",
    "x_train1, x_test1, y_train1, y_test1 = train_test_split(x_data, y_data, test_size=0.4, random_state=0)\n",
    "lre.fit(x_train1[['horsepower']],y_train1)\n",
    "lre.score(x_test1[['horsepower']],y_test1)\n",
    "\n",
    "# QUESTION 3\n",
    "Rc=cross_val_score(lre,x_data[['horsepower']], y_data,cv=2)\n",
    "Rc.mean()\n",
    "\n",
    "# QUESTION 4A\n",
    "pr1=PolynomialFeatures(degree=2)\n",
    "\n",
    "# QUESTION 4B\n",
    "x_train_pr1=pr1.fit_transform(x_train[['horsepower', 'curb-weight', 'engine-size', 'highway-mpg']])\n",
    "\n",
    "x_test_pr1=pr1.fit_transform(x_test[['horsepower', 'curb-weight', 'engine-size', 'highway-mpg']])\n",
    "\n",
    "# QUESTION 4C\n",
    "x_train_pr1.shape #there are now 15 features\n",
    "\n",
    "# QUESTION 4D\n",
    "poly1=LinearRegression().fit(x_train_pr1,y_train)\n",
    "\n",
    "# QUESTION 4E\n",
    "yhat_test1=poly1.predict(x_test_pr1)\n",
    "\n",
    "Title='Distribution  Plot of  Predicted Value Using Test Data vs Data Distribution of Test Data'\n",
    "\n",
    "DistributionPlot(y_test, yhat_test1, \"Actual Values (Test)\", \"Predicted Values (Test)\", Title)\n",
    "\n",
    "# QUESTION 5\n",
    "RigeModel = Ridge(alpha=10) \n",
    "RigeModel.fit(x_train_pr, y_train)\n",
    "RigeModel.score(x_test_pr, y_test)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "354e784a916aaee76a68cf4b3e5e447da2064fc6832da6b69572a584dad79a14"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
